{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad963dc5-3351-4331-bb2b-0d969aa07557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from transformers import *\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import timm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e704f23-35b0-49a1-8cad-6468c739813e",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "762f6f6f-2a6f-40d7-b090-002cd4665261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file preprocessor_config.json from cache at /home/moose/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/3f49326eb077187dfe1c2a2bb15fbd74e6ab91e3/preprocessor_config.json\n",
      "size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "Image processor ViTImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d71cff2fc444c54a6c0ac29b332235b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/14462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform(examples):\n",
    "  inputs = image_processor([img.convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
    "  inputs[\"labels\"] = examples[\"label\"]\n",
    "  return inputs\n",
    "\n",
    "def collate_fn(batch):\n",
    "  return {\n",
    "      \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
    "      \"labels\": torch.tensor([x[\"labels\"] for x in batch]),\n",
    "  }\n",
    "\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "batch_size = 16\n",
    "cpu_count=multiprocessing.cpu_count()\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "train_ds= load_dataset('../../../Desktop_SIH/SIH/Main_Dataset/')\n",
    "train_ds = train_ds[\"train\"].train_test_split(test_size=0.25) \n",
    "\n",
    "\n",
    "#train_ds= load_dataset('chest_xray/train/',num_proc=cpu_count)\n",
    "#test_ds= load_dataset('chest_xray/test/',num_proc=cpu_count)\n",
    "\n",
    "labels = train_ds[\"train\"].features[\"label\"].names\n",
    "#dataset_train = train_ds.with_transform(transform)\n",
    "#dataset_test=test_ds.with_transform(transform)\n",
    "dataset = train_ds.with_transform(transform)\n",
    "\n",
    "\n",
    "train_dataset_loader = torch.utils.data.DataLoader(dataset[\"train\"], collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset_loader = torch.utils.data.DataLoader(dataset[\"test\"], collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#train_dataset_loader = torch.utils.data.DataLoader(dataset_train[\"train\"], collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
    "#valid_dataset_loader = torch.utils.data.DataLoader(dataset_test[\"train\"], collate_fn=collate_fn, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c3329-d837-40b5-9519-368cd946b772",
   "metadata": {},
   "source": [
    "## Model Cr\n",
    "eation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f962d795-a991-44c3-840e-c79cee539da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"vit_base_patch16_384.orig_in21k_ft_in1k\"\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88918f3b-3b02-437a-8546-9945b9447341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((768,), eps=1e-06, elementwise_affine=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[len(model.blocks)-1].norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a0ac765-87fd-4631-b2d1-250c936a0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.blocks[len(model.blocks)-1]=torch.nn.Linear(in_features=768,out_features=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "478d09f7-78ad-4be3-901a-43b18158a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.blocks[0]=torch.nn.Linear(in_features=768,out_features=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96400c69-1a73-42af-b77d-10d4bb1f6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.blocks[1].attn.qkv=torch.nn.Linear(in_features=768,out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "635a9936-0eb3-45d9-ba68-8531c5a0e561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (1): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (2): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (3): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (4): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (5): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (6): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (7): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (8): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (9): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (10): Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       "  (11): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93670515-1968-4e11-864e-ac49b63d7e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=1, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "df3f310f-51d4-4a08-806d-393158c020ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.5241e-03,  1.3605e-02, -2.5943e-01, -1.5176e-02,  4.0256e-01,\n",
       "           4.6956e-02, -7.6992e-03,  1.1583e-02,  4.1794e-02, -2.2618e-01,\n",
       "          -8.6113e-03, -1.3967e-02, -1.5123e-02, -1.3010e-02, -2.0492e-02,\n",
       "          -8.5839e-03,  3.3414e-03,  5.7678e-02,  3.6365e-02, -5.6758e-03,\n",
       "          -4.7974e-02,  5.9637e-03, -5.0221e-03, -1.3371e-02, -6.9871e-03,\n",
       "           5.0253e-02,  7.3932e-03, -5.7437e-03,  2.1240e-02, -1.8942e-02,\n",
       "           1.5181e-03,  2.5193e-02, -2.0468e-02,  1.6701e-02,  1.9216e-02,\n",
       "          -9.3600e-04,  5.2248e-02,  9.3180e-03, -4.8390e-03,  1.8174e-03,\n",
       "           1.4953e-02,  1.0364e-02,  1.7181e-02, -2.5523e-03,  6.5110e-02,\n",
       "           4.3907e-01,  1.6787e-02,  4.5343e-03,  1.9626e-02, -1.3791e-03,\n",
       "          -5.4258e-03, -4.4043e-02,  3.1062e-03, -1.2638e-02,  8.5818e-03,\n",
       "          -7.1245e-03,  9.0131e-04, -2.6523e-03,  5.1280e-03, -7.6498e-02,\n",
       "           6.5924e-04,  2.2964e-03,  7.7230e-03,  1.2007e-02,  4.1369e-02,\n",
       "           1.1783e-02,  3.8207e-02, -1.4184e-02,  1.3703e-02,  6.5024e-02,\n",
       "          -2.7232e-02, -1.1069e-02, -2.2332e-02, -1.2420e-02,  5.2791e-02,\n",
       "           7.8236e-03,  3.7837e-03, -9.4071e-03, -6.7981e-03, -1.2753e-02,\n",
       "          -3.5229e-03,  9.8548e-04,  1.8634e-02, -3.8689e-03,  5.6656e-02,\n",
       "          -1.7264e-02, -5.7637e-02,  3.9323e-02, -1.0795e-02,  1.6016e-02,\n",
       "           2.2642e-02,  2.7810e-02, -2.3626e-02,  1.8002e-01,  1.3249e-03,\n",
       "          -2.9738e-03, -6.3270e-03,  3.1282e-03, -9.9180e-04, -4.8801e-02,\n",
       "           1.5507e-03, -1.7951e-02, -3.6016e-03,  5.4611e-03, -4.0790e-03,\n",
       "          -1.7892e-02, -5.9291e-03,  2.4333e-03, -5.0140e-02, -5.1347e-03,\n",
       "           4.5609e-01, -1.8766e-02, -1.2297e-03,  4.1024e-03,  4.1191e-02,\n",
       "           7.7481e-02, -1.2302e-02, -6.4841e-03, -1.8240e-03,  4.3855e-03,\n",
       "           4.9990e-03, -8.5829e-03, -1.2921e-02, -1.0779e-02, -1.3884e-02,\n",
       "          -2.0358e-02,  1.0455e-02, -1.6950e-02,  1.2208e-02,  2.0826e-01,\n",
       "           1.9971e-02,  4.3425e-03, -1.0434e-02,  1.7700e-03,  1.7465e-03,\n",
       "          -1.3822e-02,  1.5103e-03,  1.2857e-02, -1.5198e-02,  1.3914e-04,\n",
       "           2.6919e-02, -8.6628e-04, -1.0232e-02, -3.4687e-02, -3.6336e-02,\n",
       "          -1.9522e-02,  7.2087e-03,  6.6522e-03,  7.9323e-03, -2.8293e-03,\n",
       "           3.8676e-04, -3.7287e-02, -1.2664e-03, -3.0015e-02,  6.4105e-04,\n",
       "          -1.5670e-01, -9.3375e-03,  6.1370e-03, -2.3274e-02,  3.1120e-02,\n",
       "          -1.5021e-02, -1.3629e-02,  5.3411e-03,  3.7205e-03, -7.1907e-04,\n",
       "           4.9126e-02,  7.6359e-03, -2.8245e-02, -6.7872e-03, -3.6331e-03,\n",
       "          -1.1503e-02,  4.4648e-03, -8.7776e-03, -5.0347e-03, -8.2647e-03,\n",
       "           1.2684e-02,  9.6628e-03, -4.9963e-03, -1.5185e-03, -2.0758e-02,\n",
       "          -4.4227e-01, -1.6605e-02, -3.0361e-03,  3.5549e-03, -2.3234e-02,\n",
       "          -1.0877e-03,  2.0660e-02,  2.7947e-01, -1.0994e-02,  7.3686e-03,\n",
       "           5.7143e-04,  1.0532e-02,  1.7340e-02, -2.5639e-02, -3.3947e-03,\n",
       "          -4.6617e-02, -8.1456e-03,  3.0122e-02, -3.1929e-03,  4.7756e-03,\n",
       "           1.8465e-03,  4.5096e-01,  3.8460e-03, -1.5178e-03,  1.9032e-02,\n",
       "          -7.6966e-02, -1.4014e-02,  9.7293e-02, -1.5440e-02,  8.0154e-03,\n",
       "           4.0820e-03, -3.2655e-02, -6.6323e-03, -3.9195e-03, -5.1480e-03,\n",
       "           4.9198e-03, -1.1998e-02, -6.6572e-03,  3.4275e-03,  5.0555e-02,\n",
       "          -1.1799e-02, -2.3423e-02,  1.5893e-03,  1.4074e-03,  1.1078e-02,\n",
       "          -1.4214e-02, -4.7792e-02, -1.2107e-02, -8.9469e-02,  1.0190e-03,\n",
       "           1.1467e-02,  2.7622e-02,  3.4231e-02,  9.9680e-03, -2.8606e-01,\n",
       "          -1.8101e-01, -3.3521e-02,  4.6874e-03,  2.2188e-03,  4.8443e-02,\n",
       "          -1.8535e-02, -1.9271e-02, -1.3435e-03, -6.8161e-03,  1.4162e-02,\n",
       "           1.6454e-02, -3.3878e-02, -1.7982e-01,  2.9807e-02,  3.9493e-03,\n",
       "          -2.8324e-02,  5.3209e-01,  1.2112e-02, -2.0573e-02,  9.6612e-03,\n",
       "           4.0953e-02, -1.6736e-02,  3.2608e-02, -5.1247e-03,  8.8172e-03,\n",
       "           7.7078e-03,  1.4267e-02, -7.3331e-03, -2.9722e-02, -4.1541e-03,\n",
       "           2.7339e-02, -2.3490e-02,  1.2850e-02,  2.8287e-02,  4.6395e-03,\n",
       "          -2.8581e-02, -3.7632e-02, -1.9655e-01,  1.3022e-02,  7.7933e-04,\n",
       "           7.5460e-03,  1.2930e-02, -1.0188e-02, -3.3391e-01,  1.0111e-01,\n",
       "           3.6448e-03,  2.0060e-02, -2.0246e-03, -1.3804e-02,  9.0684e-03,\n",
       "          -4.9943e-02, -2.0221e-02, -2.5239e-03,  4.0953e-02,  1.0877e-02,\n",
       "          -9.2839e-04, -3.1257e-02, -1.5416e-02,  5.9924e-03,  3.8566e-02,\n",
       "           1.6622e-02, -1.5124e-02,  2.1768e-02,  4.4462e-03, -4.4805e-03,\n",
       "          -2.2076e-02, -4.9559e-02, -1.4071e-02, -2.8533e-02, -2.6873e-02,\n",
       "          -1.0459e-03, -5.4149e-03,  7.4180e-03,  6.3429e-03, -1.1827e-02,\n",
       "           8.1793e-03,  1.1001e-02, -3.9525e-02,  5.7277e-03,  4.6737e-02,\n",
       "          -5.2100e-03,  1.4337e-02,  7.5300e-04, -4.9496e-02, -1.0044e-02,\n",
       "           2.4214e-01, -8.0281e-03,  5.6485e-04, -1.5236e-02,  1.5887e-03,\n",
       "           9.9935e-02,  3.4870e-03, -6.8713e-03,  1.0500e-03, -4.4672e-02,\n",
       "           2.0636e-03,  2.5442e-05,  4.0763e-03,  1.3719e-02,  2.5625e-02,\n",
       "           6.2052e-03, -3.0186e-02,  9.8100e-03, -2.8651e-02,  9.9293e-03,\n",
       "          -1.3505e-01, -1.0061e-02, -7.6064e-02,  9.6825e-03,  6.4809e-03,\n",
       "           2.5030e-01,  3.1004e-02, -1.1869e-04,  4.3465e-03, -4.7388e-02,\n",
       "           7.3032e-03,  6.1566e-03,  5.8262e-01, -1.1655e-02,  3.2651e-03,\n",
       "          -8.7824e-03, -2.2915e-02, -1.0698e-01,  6.7495e-03,  1.4389e-02,\n",
       "           5.0880e-02,  2.0722e-03, -3.9820e-02,  1.3845e-03,  1.6886e-01,\n",
       "          -6.2908e-03, -9.6682e-03, -8.3112e-03,  1.8760e-02, -2.4539e-02,\n",
       "           1.6224e-02, -2.6386e-02,  1.2949e-02,  4.6323e-03, -9.2223e-02,\n",
       "          -7.9073e-03,  1.8185e-02, -4.0335e-03,  1.8858e-02, -1.0917e-03,\n",
       "          -4.6377e-03, -2.0340e-03,  9.1051e-01, -3.9159e-02,  2.6318e-02,\n",
       "          -4.9387e-03,  3.5032e-03,  2.3902e-03,  3.4520e-02,  2.9036e-02,\n",
       "           8.0820e-03, -1.8548e-02,  1.3656e-02, -2.7925e-03,  1.9674e-02,\n",
       "           1.8832e-02,  9.2207e-03, -1.2873e-02, -1.5912e-01, -2.3933e-02,\n",
       "           3.5845e-03,  5.9231e-02, -1.4283e-02, -7.2305e-03,  1.3875e-02,\n",
       "          -9.1712e-05, -4.1006e-01, -1.2699e-02,  7.9195e-03, -1.1037e-02,\n",
       "          -4.1530e-02,  7.4480e-03,  1.7136e-02,  1.8407e-02, -5.5631e-02,\n",
       "          -4.9231e-02, -1.8380e-02,  3.6856e-02,  5.1818e-02, -1.3886e-02,\n",
       "          -3.8086e-03,  1.9834e-03, -1.7128e-02,  7.3210e-03, -6.7701e-02,\n",
       "          -7.6492e-03,  5.7886e-03,  3.7055e-02,  9.4228e-03,  2.3391e-03,\n",
       "           2.8295e-04,  3.3071e-02,  1.4809e-02,  6.7014e-03,  3.9956e-03,\n",
       "           1.3986e-02, -5.1017e-03,  6.9583e-04,  1.1457e-02, -1.0160e-02,\n",
       "           1.9732e-02,  3.9828e-04,  9.7222e-03, -9.8822e-03, -4.3799e-03,\n",
       "           1.0740e-02, -1.2591e-03, -4.2797e-02, -6.4914e-02, -4.1443e-01,\n",
       "          -4.4535e-03, -4.1687e-03, -1.5116e-02, -1.5250e-02,  5.0405e-02,\n",
       "          -4.6363e-02,  2.3127e-03, -2.1639e-02, -1.6889e-01, -4.9795e-02,\n",
       "           1.3589e-02, -2.0289e-03,  4.2337e-03,  3.7946e-03, -2.6875e-02,\n",
       "           3.4209e-02, -5.5902e-03,  1.1901e-01,  1.4273e-02,  1.2244e-02,\n",
       "          -1.3773e-02,  2.2134e-01,  9.2086e-04,  2.5562e-02, -6.0596e-02,\n",
       "          -5.0033e-03, -1.0802e-02,  7.1728e-03, -2.1143e-02,  3.2457e-03,\n",
       "          -5.5994e-03, -3.5471e-02, -3.4237e-03,  7.1375e-03,  1.0879e-02,\n",
       "          -2.0945e-02, -9.9020e-03,  3.6885e-02,  5.0370e-03,  4.0917e-01,\n",
       "          -3.5771e-02, -1.2591e-02,  4.8092e-03, -2.0365e-02, -1.8301e-02,\n",
       "           7.6741e-02,  2.7699e-03, -2.1140e-02,  1.5077e-02, -9.5022e-03,\n",
       "           1.7700e-02, -9.7814e-03, -2.3262e-02, -4.8472e-03, -3.4199e-02,\n",
       "           5.3005e-02,  2.2387e-02, -4.5017e-02,  2.2663e-02, -4.3352e-03,\n",
       "           1.6243e-02, -3.4561e-02, -2.0650e-01, -1.5092e-02,  1.6386e-02,\n",
       "           3.8667e-03,  4.5319e-01, -7.8600e-03, -1.5052e-01,  2.2550e-02,\n",
       "           2.1496e-02,  1.2976e-02,  4.9623e-02,  3.1835e-02, -1.3775e-03,\n",
       "           1.5241e-02,  1.0257e-03, -1.9062e-02, -7.7814e-03,  1.0361e-01,\n",
       "          -7.8586e-03, -9.4880e-03,  7.5525e-03,  1.9582e-03,  1.2422e-02,\n",
       "           2.1343e-02, -8.7230e-05, -1.2864e-02,  1.1128e-02,  1.3259e-04,\n",
       "          -3.9742e-03, -2.3646e-02,  1.8825e-03, -1.2549e-02,  4.6157e-03,\n",
       "          -6.1573e-03,  3.7196e-02, -2.0232e-02,  1.4568e-02, -4.9747e-02,\n",
       "          -9.8488e-04, -7.8851e-03,  1.6992e-02, -9.6067e-03,  6.0269e-03,\n",
       "           1.3009e-02, -6.4267e-02,  2.2216e-03, -2.2861e-01,  1.4262e-03,\n",
       "           6.2323e-04, -2.6413e-03, -7.9579e-03, -2.4202e-03, -4.7296e-02,\n",
       "          -8.6579e-03,  2.1361e-03,  1.2969e-03,  1.2499e-02,  1.0010e-01,\n",
       "          -2.0712e-02, -7.2085e-03,  3.3765e-03,  2.1151e-02, -2.5243e-02,\n",
       "          -2.0664e-03, -5.6490e-02, -1.9661e-03,  6.8204e-03, -4.9031e-03,\n",
       "           7.0813e-03,  1.0828e-02,  4.6223e-03, -9.7403e-04,  1.4656e-02,\n",
       "           4.2226e-02,  2.8479e-03,  1.1628e-01, -5.5048e-03,  3.3214e-04,\n",
       "          -6.3737e-03,  5.3653e-03,  1.7947e-02, -2.6757e-02,  2.0636e-02,\n",
       "          -7.9195e-03, -6.7083e-04, -5.1874e-03, -3.2128e-02, -1.8123e-02,\n",
       "           3.4751e-02,  4.5761e-03, -7.7452e-03, -1.5263e-03,  1.4007e-02,\n",
       "          -1.6724e-02,  3.6303e-03, -3.1863e-02, -7.7693e-03, -8.0139e-03,\n",
       "           9.7181e-03,  1.1539e-02, -8.4120e-02,  1.2512e-01, -2.4722e-02,\n",
       "          -1.4053e-03,  2.9692e-04,  1.0019e-02,  8.3164e-03, -5.3238e-03,\n",
       "          -1.7012e-01,  1.3938e-02, -8.7112e-02, -6.3088e-03,  7.9862e-03,\n",
       "           4.0872e-04, -1.2629e-01, -1.4388e-01, -3.3934e-01, -8.3254e-03,\n",
       "           1.6860e-03,  1.2162e-02,  1.8071e-02,  4.5667e-03,  4.8611e-02,\n",
       "          -3.9852e-03, -1.6915e-02,  1.5601e-01,  3.9244e-02, -1.2971e-02,\n",
       "          -8.7139e-04, -2.5515e-02, -2.1842e-03,  7.7919e-02, -1.8473e-02,\n",
       "           5.4383e-01,  8.1576e-03,  1.4384e-02, -6.8943e-03,  8.9419e-03,\n",
       "          -1.4113e-01,  1.0506e-02,  1.2668e-01, -7.1958e-03,  3.4074e-02,\n",
       "          -1.9902e-02, -3.4152e-02,  6.7613e-03,  8.6462e-02,  4.9520e-04,\n",
       "           3.6039e-03,  1.5097e-02,  2.4561e-02, -4.1652e-04, -3.3130e-03,\n",
       "          -8.6064e-03,  3.5222e-03, -7.7380e-03,  1.7022e-02, -5.2109e-03,\n",
       "          -4.6731e-01, -1.1261e-02,  1.2676e-01, -3.2659e-02,  7.3306e-03,\n",
       "          -1.6079e-02,  1.9988e-02, -2.8776e-02,  7.8672e-01,  5.4034e-03,\n",
       "           4.2226e-03,  6.4473e-03,  1.5808e-03,  1.6927e-02,  5.3914e-03,\n",
       "           5.8306e-03,  6.7648e-02,  2.0964e-02,  1.2026e-02, -9.0589e-03,\n",
       "          -4.4479e-03, -1.7207e-04,  2.2389e-02, -1.6876e-02,  1.1506e-02,\n",
       "           1.0646e-02, -8.0850e-04,  1.5212e-03, -3.1003e-03, -6.8997e-03,\n",
       "           2.1622e-02,  8.3585e-03,  2.6053e-02,  5.3740e-03,  7.3236e-04,\n",
       "           6.1919e-02,  1.7465e-01,  4.3283e-03,  6.4874e-03,  1.7233e-02,\n",
       "           3.2486e-03, -4.3128e-03,  2.1316e-02,  5.0354e-03, -3.0395e-01,\n",
       "           6.2084e-03,  2.8053e-02, -3.1808e-03, -1.0974e-04,  2.0570e-02,\n",
       "           1.7487e-02, -2.0689e-03, -1.7962e-05,  3.7524e-03,  1.3551e-02,\n",
       "          -5.3001e-03,  8.5406e-02,  2.8220e-03, -4.8623e-02, -8.8248e-03,\n",
       "           3.5139e-04,  2.4568e-04,  5.0686e-03, -1.4712e-02, -1.0154e-01,\n",
       "           2.8767e-03, -1.4657e-02, -8.8952e-03, -1.1671e-02, -6.2045e-03,\n",
       "           3.7206e-03, -1.5396e-02, -3.2103e-02,  6.8546e-03, -6.8226e-02,\n",
       "           4.7042e-03,  2.8786e-02, -5.7796e-04, -2.6871e-03,  2.0720e-02,\n",
       "           4.6309e-03,  1.3495e-02,  9.0799e-03,  1.8464e-04,  6.7215e-02,\n",
       "          -9.0265e-02, -1.0745e-02,  1.0550e-02,  2.3855e-02, -5.4646e-01,\n",
       "           4.8041e-03, -1.1691e-02, -1.7081e-02, -2.6669e-02,  1.9243e-02,\n",
       "          -6.6476e-03,  4.8615e-03, -4.0433e-01]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.state_dict())[\"cls_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227896bd-12c9-4ae6-851b-f50bdaa497c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
